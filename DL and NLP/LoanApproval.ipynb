{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nWGQ-Egy5jld"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "X= df"
      ],
      "metadata": {
        "id": "_h3zFpZv50Gs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "1P07gqpn6DdU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def preprocess(df):\n",
        "    df['person_emp_length'] = df['person_emp_length'].fillna(df['person_emp_length'].mean())\n",
        "    df['loan_int_rate'] = df['loan_int_rate'].fillna(df['loan_int_rate'].mean())\n",
        "\n",
        "    df['person_emp_length'].replace(0, np.nan, inplace=True)\n",
        "    df['person_income'].replace(0, np.nan, inplace=True)\n",
        "\n",
        "    df['person_emp_length'].fillna(df['person_emp_length'].mean(), inplace=True)\n",
        "    df['person_income'].fillna(df['person_income'].mean(), inplace=True)\n",
        "\n",
        "    df['loan_to_income'] = (df['loan_amnt'] / df['person_income']) - df['loan_percent_income']\n",
        "    df['age_income_interaction'] = df['person_age'] * df['person_income']\n",
        "    df['loan_to_emp_length_ratio'] = df['loan_amnt'] / df['person_emp_length']\n",
        "\n",
        "    monthly_income = df['person_income'] / 12\n",
        "    df['monthly_debt'] = df['loan_amnt'] * (1 + df['loan_int_rate']) / 12\n",
        "    df['dti_ratio'] = df['monthly_debt'] / monthly_income\n",
        "\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    new_features = ['loan_to_income', 'age_income_interaction', 'loan_to_emp_length_ratio',\n",
        "                    'monthly_debt', 'dti_ratio']\n",
        "    df[new_features] = df[new_features].fillna(df[new_features].mean())\n",
        "\n",
        "    df['risk_flag'] = np.where(\n",
        "        (df['cb_person_default_on_file'] == 'Y') & (df['loan_grade'].isin(['C', 'D', 'E'])),\n",
        "        1,\n",
        "        0\n",
        "    )\n",
        "\n",
        "    categorical_columns = [\n",
        "        'person_home_ownership', 'loan_intent', 'loan_grade',\n",
        "        'cb_person_default_on_file'\n",
        "    ]\n",
        "    for col in categorical_columns:\n",
        "        df[col] = df[col].astype('category')\n",
        "\n",
        "    numeric_columns = [\n",
        "        'loan_to_income', 'age_income_interaction', 'loan_to_emp_length_ratio',\n",
        "        'monthly_debt', 'dti_ratio', 'risk_flag'\n",
        "    ]\n",
        "    for col in numeric_columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    numerical_cols = df.select_dtypes(include=np.number).columns\n",
        "    df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())\n"
      ],
      "metadata": {
        "id": "VHiVAzAu56VE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(X)\n",
        "preprocess(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mYlj6nE56Rt",
        "outputId": "99ba454e-dea7-479b-abda-09e41de16f68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-2d085a73538f>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_emp_length'].replace(0, np.nan, inplace=True)\n",
            "<ipython-input-3-2d085a73538f>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_income'].replace(0, np.nan, inplace=True)\n",
            "<ipython-input-3-2d085a73538f>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_emp_length'].fillna(df['person_emp_length'].mean(), inplace=True)\n",
            "<ipython-input-3-2d085a73538f>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_income'].fillna(df['person_income'].mean(), inplace=True)\n",
            "<ipython-input-3-2d085a73538f>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_emp_length'].replace(0, np.nan, inplace=True)\n",
            "<ipython-input-3-2d085a73538f>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_income'].replace(0, np.nan, inplace=True)\n",
            "<ipython-input-3-2d085a73538f>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_emp_length'].fillna(df['person_emp_length'].mean(), inplace=True)\n",
            "<ipython-input-3-2d085a73538f>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_income'].fillna(df['person_income'].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = X.pop('loan_status')"
      ],
      "metadata": {
        "id": "KJAUrdDF56Px"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "# 6. Remove Outliers\n",
        "def remove_outliers_iqr(df, columns, target_variable=None):\n",
        "    for col in columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "    if target_variable is not None:\n",
        "        # Select target rows based on remaining indices in df\n",
        "        aligned_target = target_variable.loc[df.index]\n",
        "        # Reset index for both to avoid potential index mismatch later\n",
        "        df = df.reset_index(drop=True)\n",
        "        aligned_target = aligned_target.reset_index(drop=True)\n",
        "        return df, aligned_target\n",
        "    return df\n",
        "\n",
        "X_no_outliers, y_no_outliers = remove_outliers_iqr(X, numerical_cols, target_variable=y)\n",
        "\n",
        "# 7. Encoding Categorical Variables\n",
        "X_no_outliers = pd.get_dummies(X_no_outliers, drop_first=True)\n",
        "test = pd.get_dummies(test, drop_first=True)\n",
        "\n",
        "# Align the columns of X_no_outliers and test\n",
        "X_no_outliers, test = X_no_outliers.align(test, join='outer', axis=1, fill_value=0)\n",
        "\n",
        "# Handle any new infinite or NaN values after encoding\n",
        "X_no_outliers.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_no_outliers.fillna(X_no_outliers.mean(), inplace=True)\n",
        "test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "test.fillna(test.mean(), inplace=True)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_np = X_no_outliers.values\n",
        "y_np = y_no_outliers.values"
      ],
      "metadata": {
        "id": "mt0NCi9Q56Nx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_dim):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid') # Use sigmoid activation because we are predicting 0 and 1's\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# 9. 5-Fold Cross-Validation and Collecting Test Predictions\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Initialize StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Arrays to store the performance metrics and test predictions for each fold\n",
        "fold_accuracy = []\n",
        "fold_loss = []\n",
        "test_preds = []\n",
        "\n",
        "# Early Stopping Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(X_np, y_np)):\n",
        "    print(f\"\\nFold {fold + 1}\")\n",
        "\n",
        "    # Split data\n",
        "    X_train_fold, X_val_fold = X_np[train_index], X_np[val_index]\n",
        "    y_train_fold, y_val_fold = y_np[train_index], y_np[val_index]\n",
        "\n",
        "    # Feature Scaling within each fold\n",
        "    scaler = StandardScaler()\n",
        "    X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
        "    X_val_fold_scaled = scaler.transform(X_val_fold)\n",
        "    test_scaled = scaler.transform(test.values)\n",
        "\n",
        "    # Build the model\n",
        "    model = create_model(input_dim=X_train_fold_scaled.shape[1])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train_fold_scaled, y_train_fold,\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_val_fold_scaled, y_val_fold),\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X_val_fold_scaled, y_val_fold, verbose=0)\n",
        "    print(f'Validation Loss for fold {fold + 1}: {loss:.4f}')\n",
        "    print(f'Validation Accuracy for fold {fold + 1}: {accuracy:.4f}')\n",
        "\n",
        "    fold_accuracy.append(accuracy)\n",
        "    fold_loss.append(loss)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    test_pred = model.predict(test_scaled)\n",
        "    test_preds.append(test_pred)\n",
        "\n",
        "# After all folds\n",
        "print('\\nCross-validation results:')\n",
        "print(f'Average Validation Accuracy: {np.mean(fold_accuracy):.4f}')\n",
        "print(f'Standard Deviation of Validation Accuracy: {np.std(fold_accuracy):.4f}')\n",
        "print(f'Average Validation Loss: {np.mean(fold_loss):.4f}')\n",
        "print(f'Standard Deviation of Validation Loss: {np.std(fold_loss):.4f}')\n",
        "\n",
        "# Aggregate test predictions\n",
        "test_preds = np.array(test_preds)  # Shape: (n_folds, n_samples, 1)\n",
        "# Average the predictions across folds\n",
        "test_predictions_mean = np.mean(test_preds, axis=0).flatten()\n",
        "\n",
        "# Convert averaged predictions to binary\n",
        "test_predictions_binary = (test_predictions_mean >= 0.5).astype(int)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f87SiWdH56Ls",
        "outputId": "29458835-c86d-4a30-a2d7-129f5056a8c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8888 - loss: 0.3715 - val_accuracy: 0.9260 - val_loss: 0.1924\n",
            "Epoch 2/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2429 - val_accuracy: 0.9260 - val_loss: 0.1838\n",
            "Epoch 3/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.2180 - val_accuracy: 0.9347 - val_loss: 0.1777\n",
            "Epoch 4/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9341 - loss: 0.2048 - val_accuracy: 0.9414 - val_loss: 0.1725\n",
            "Epoch 5/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9322 - loss: 0.2052 - val_accuracy: 0.9373 - val_loss: 0.1727\n",
            "Epoch 6/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9356 - loss: 0.1941 - val_accuracy: 0.9450 - val_loss: 0.1651\n",
            "Epoch 7/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.1892 - val_accuracy: 0.9454 - val_loss: 0.1649\n",
            "Epoch 8/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.1933 - val_accuracy: 0.9471 - val_loss: 0.1619\n",
            "Epoch 9/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.1794 - val_accuracy: 0.9493 - val_loss: 0.1647\n",
            "Epoch 10/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.1849 - val_accuracy: 0.9447 - val_loss: 0.1629\n",
            "Epoch 11/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9427 - loss: 0.1814 - val_accuracy: 0.9498 - val_loss: 0.1627\n",
            "Epoch 12/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9418 - loss: 0.1801 - val_accuracy: 0.9501 - val_loss: 0.1630\n",
            "Epoch 13/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.1820 - val_accuracy: 0.9530 - val_loss: 0.1540\n",
            "Epoch 14/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1756 - val_accuracy: 0.9525 - val_loss: 0.1551\n",
            "Epoch 15/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.1778 - val_accuracy: 0.9530 - val_loss: 0.1547\n",
            "Epoch 16/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9458 - loss: 0.1783 - val_accuracy: 0.9534 - val_loss: 0.1519\n",
            "Epoch 17/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1738 - val_accuracy: 0.9532 - val_loss: 0.1531\n",
            "Epoch 18/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.1767 - val_accuracy: 0.9524 - val_loss: 0.1545\n",
            "Epoch 19/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1768 - val_accuracy: 0.9550 - val_loss: 0.1510\n",
            "Epoch 20/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9458 - loss: 0.1779 - val_accuracy: 0.9535 - val_loss: 0.1549\n",
            "Epoch 21/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9463 - loss: 0.1704 - val_accuracy: 0.9541 - val_loss: 0.1517\n",
            "Epoch 22/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.1699 - val_accuracy: 0.9545 - val_loss: 0.1532\n",
            "Epoch 23/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9515 - loss: 0.1631 - val_accuracy: 0.9542 - val_loss: 0.1515\n",
            "Epoch 24/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1708 - val_accuracy: 0.9535 - val_loss: 0.1548\n",
            "Validation Loss for fold 1: 0.1510\n",
            "Validation Accuracy for fold 1: 0.9550\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\n",
            "Fold 2\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8921 - loss: 0.3689 - val_accuracy: 0.9260 - val_loss: 0.2081\n",
            "Epoch 2/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.2351 - val_accuracy: 0.9260 - val_loss: 0.1930\n",
            "Epoch 3/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.2158 - val_accuracy: 0.9267 - val_loss: 0.1873\n",
            "Epoch 4/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9324 - loss: 0.2012 - val_accuracy: 0.9277 - val_loss: 0.1862\n",
            "Epoch 5/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9322 - loss: 0.2038 - val_accuracy: 0.9287 - val_loss: 0.1852\n",
            "Validation Loss for fold 2: 0.2081\n",
            "Validation Accuracy for fold 2: 0.9260\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\n",
            "Fold 3\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.4376 - val_accuracy: 0.9269 - val_loss: 0.1938\n",
            "Epoch 2/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9299 - loss: 0.2362 - val_accuracy: 0.9276 - val_loss: 0.1872\n",
            "Epoch 3/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2277 - val_accuracy: 0.9276 - val_loss: 0.1832\n",
            "Epoch 4/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9330 - loss: 0.2109 - val_accuracy: 0.9316 - val_loss: 0.1802\n",
            "Epoch 5/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9360 - loss: 0.1968 - val_accuracy: 0.9389 - val_loss: 0.1720\n",
            "Validation Loss for fold 3: 0.1938\n",
            "Validation Accuracy for fold 3: 0.9269\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\n",
            "Fold 4\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.3831 - val_accuracy: 0.9260 - val_loss: 0.1927\n",
            "Epoch 2/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9277 - loss: 0.2448 - val_accuracy: 0.9273 - val_loss: 0.1856\n",
            "Epoch 3/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9288 - loss: 0.2195 - val_accuracy: 0.9279 - val_loss: 0.1825\n",
            "Epoch 4/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9310 - loss: 0.2103 - val_accuracy: 0.9304 - val_loss: 0.1798\n",
            "Epoch 5/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9365 - loss: 0.1955 - val_accuracy: 0.9369 - val_loss: 0.1770\n",
            "Validation Loss for fold 4: 0.1927\n",
            "Validation Accuracy for fold 4: 0.9260\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
            "\n",
            "Fold 5\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7439 - loss: 0.5371 - val_accuracy: 0.9260 - val_loss: 0.1993\n",
            "Epoch 2/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2477 - val_accuracy: 0.9273 - val_loss: 0.1806\n",
            "Epoch 3/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.2209 - val_accuracy: 0.9304 - val_loss: 0.1776\n",
            "Epoch 4/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9320 - loss: 0.2065 - val_accuracy: 0.9306 - val_loss: 0.1712\n",
            "Epoch 5/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.2072 - val_accuracy: 0.9361 - val_loss: 0.1701\n",
            "Validation Loss for fold 5: 0.1993\n",
            "Validation Accuracy for fold 5: 0.9260\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\n",
            "Cross-validation results:\n",
            "Average Validation Accuracy: 0.9320\n",
            "Standard Deviation of Validation Accuracy: 0.0115\n",
            "Average Validation Loss: 0.1890\n",
            "Standard Deviation of Validation Loss: 0.0198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMr4WzSi56Jp",
        "outputId": "32e28b3e-cec6-4392-c3e6-6c92e5983c9f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.40621036, 0.03717132, 0.2952488 , ..., 0.02677658, 0.24226694,\n",
              "       0.43698555], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_user_input(user_input_dict):\n",
        "    # Convert the dictionary to a DataFrame\n",
        "    user_input_df = pd.DataFrame([user_input_dict])\n",
        "\n",
        "    # Preprocess the input data (same as the training data preprocessing)\n",
        "    preprocess(user_input_df)\n",
        "\n",
        "    # Handle categorical columns (same as in preprocessing)\n",
        "    user_input_df = pd.get_dummies(user_input_df, drop_first=True)\n",
        "\n",
        "    # Align with the training dataset (handle any columns that might be missing)\n",
        "    user_input_df = user_input_df.reindex(columns=X_no_outliers.columns, fill_value=0)\n",
        "\n",
        "    # Handle any new infinite or NaN values after encoding\n",
        "    user_input_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    user_input_df.fillna(user_input_df.mean(), inplace=True)\n",
        "\n",
        "    # Convert to numpy array for prediction\n",
        "    user_input_np = user_input_df.values\n",
        "    return user_input_np\n"
      ],
      "metadata": {
        "id": "26l9-wXq56Hc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_acceptance(user_input_dict):\n",
        "    # Prepare the user input\n",
        "    user_input_np = prepare_user_input(user_input_dict)\n",
        "\n",
        "    # Feature Scaling (use the scaler fitted during training)\n",
        "    user_input_scaled = scaler.transform(user_input_np)\n",
        "\n",
        "    # Get the model's prediction (probability)\n",
        "    pred_prob = model.predict(user_input_scaled)\n",
        "\n",
        "    # Output the probability (mean acceptance rate)\n",
        "    acceptance_prob = pred_prob[0][0]  # Single prediction\n",
        "    return acceptance_prob\n"
      ],
      "metadata": {
        "id": "25sp6KXZ56E_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = {\n",
        "    'person_age': 35,\n",
        "    'person_income': 60000,\n",
        "    'person_home_ownership': 'MORTGAGE',  # Categorical value\n",
        "    'person_emp_length': 10,\n",
        "    'loan_intent': 'PERSONAL',  # Categorical value\n",
        "    'loan_grade': 'B',  # Categorical value\n",
        "    'loan_amnt': 20000,\n",
        "    'loan_int_rate': 0.05,\n",
        "    'loan_percent_income': 0.25,\n",
        "    'cb_person_default_on_file': 'N',  # Categorical value\n",
        "    'cb_person_cred_hist_length': 5\n",
        "}\n",
        "\n",
        "# Get the predicted acceptance probability\n",
        "predicted_acceptance = predict_acceptance(user_input)\n",
        "print(f\"The predicted probability of loan approval is: {predicted_acceptance * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn8_ZynZ56C8",
        "outputId": "ef948b93-7df0-4bb9-d7bb-ff14eac59af1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-2d085a73538f>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_emp_length'].replace(0, np.nan, inplace=True)\n",
            "<ipython-input-3-2d085a73538f>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_income'].replace(0, np.nan, inplace=True)\n",
            "<ipython-input-3-2d085a73538f>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_emp_length'].fillna(df['person_emp_length'].mean(), inplace=True)\n",
            "<ipython-input-3-2d085a73538f>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['person_income'].fillna(df['person_income'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "The predicted probability of loan approval is: 0.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert the user input dictionary to a pandas DataFrame\n",
        "input_df = pd.DataFrame([user_input])\n",
        "\n",
        "# Check for missing values\n",
        "print(input_df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0m0cr7756Ai",
        "outputId": "3512a4c8-4b68-483e-98f6-62ae0b899447"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "person_age                    0\n",
            "person_income                 0\n",
            "person_home_ownership         0\n",
            "person_emp_length             0\n",
            "loan_intent                   0\n",
            "loan_grade                    0\n",
            "loan_amnt                     0\n",
            "loan_int_rate                 0\n",
            "loan_percent_income           0\n",
            "cb_person_default_on_file     0\n",
            "cb_person_cred_hist_length    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['person_emp_length'] = df['person_emp_length'].replace(0, np.nan)\n",
        "df['person_income'] = df['person_income'].replace(0, np.nan)\n",
        "df['person_income'] = df['person_income'].fillna(df['person_income'].mean())\n"
      ],
      "metadata": {
        "id": "q5Jk6v5a8vef"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_df = pd.get_dummies(input_df, columns=['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'])\n"
      ],
      "metadata": {
        "id": "WVnRA1jV8xkG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "7OwQna1R85aD",
        "outputId": "2439d11a-5dfc-4f57-e3a0-14b69d0eb922"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   person_age  person_income  person_emp_length  loan_amnt  loan_int_rate  \\\n",
              "0          37          35000                0.0       6000          11.49   \n",
              "\n",
              "   loan_percent_income  cb_person_cred_hist_length  \\\n",
              "0                 0.17                          14   \n",
              "\n",
              "   person_home_ownership_RENT  loan_intent_EDUCATION  loan_grade_B  \\\n",
              "0                        True                   True          True   \n",
              "\n",
              "   cb_person_default_on_file_N  \n",
              "0                         True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ead2ddd-4fca-4f7c-95fb-87e9c08a44bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_age</th>\n",
              "      <th>person_income</th>\n",
              "      <th>person_emp_length</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>loan_int_rate</th>\n",
              "      <th>loan_percent_income</th>\n",
              "      <th>cb_person_cred_hist_length</th>\n",
              "      <th>person_home_ownership_RENT</th>\n",
              "      <th>loan_intent_EDUCATION</th>\n",
              "      <th>loan_grade_B</th>\n",
              "      <th>cb_person_default_on_file_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37</td>\n",
              "      <td>35000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6000</td>\n",
              "      <td>11.49</td>\n",
              "      <td>0.17</td>\n",
              "      <td>14</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ead2ddd-4fca-4f7c-95fb-87e9c08a44bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ead2ddd-4fca-4f7c-95fb-87e9c08a44bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ead2ddd-4fca-4f7c-95fb-87e9c08a44bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_c4cefbf6-e318-4429-bec6-bc22a60eec55\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('input_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c4cefbf6-e318-4429-bec6-bc22a60eec55 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('input_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "input_df",
              "summary": "{\n  \"name\": \"input_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"person_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 37,\n        \"max\": 37,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          37\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"person_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 35000,\n        \"max\": 35000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          35000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"person_emp_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan_amnt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 6000,\n        \"max\": 6000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan_int_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 11.49,\n        \"max\": 11.49,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          11.49\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan_percent_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.17,\n        \"max\": 0.17,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cb_person_cred_hist_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 14,\n        \"max\": 14,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"person_home_ownership_RENT\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan_intent_EDUCATION\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan_grade_B\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cb_person_default_on_file_N\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample model function (Replace with your actual model prediction function)\n",
        "def predict_acceptance(input_data):\n",
        "    # Assuming you have a trained model, use it for prediction\n",
        "    # For demonstration purposes, let's say the model predicts a random probability\n",
        "    return np.random.random()\n",
        "\n",
        "# Preprocessing the input data\n",
        "def preprocess_input(user_input):\n",
        "    # Convert the user input dictionary to a pandas DataFrame\n",
        "    input_df = pd.DataFrame([user_input])\n",
        "\n",
        "    # Handle missing values\n",
        "    # Replace 0 in 'person_emp_length' and 'person_income' with NaN\n",
        "    input_df['person_emp_length'] = input_df['person_emp_length'].replace(0, np.nan)\n",
        "    input_df['person_income'] = input_df['person_income'].replace(0, np.nan)\n",
        "\n",
        "    # Fill missing values in 'person_income' with the mean of that column\n",
        "    input_df['person_income'] = input_df['person_income'].fillna(input_df['person_income'].mean())\n",
        "\n",
        "    # Categorical variables need to be handled before model prediction\n",
        "    # Example: Encoding categorical columns as dummy variables (One-Hot Encoding)\n",
        "    categorical_cols = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\n",
        "    input_df = pd.get_dummies(input_df, columns=categorical_cols)\n",
        "\n",
        "    return input_df\n",
        "\n",
        "# Define user input\n",
        "user_input = {\n",
        "    'person_age': 37,\n",
        "    'person_income': 35000,\n",
        "    'person_home_ownership': 'RENT',  # Categorical value\n",
        "    'person_emp_length': 0,\n",
        "    'loan_intent': 'EDUCATION',  # Categorical value\n",
        "    'loan_grade': 'B',  # Categorical value\n",
        "    'loan_amnt': 6000,\n",
        "    'loan_int_rate': 11.49,\n",
        "    'loan_percent_income': 0.17,\n",
        "    'cb_person_default_on_file': 'N',  # Categorical value\n",
        "    'cb_person_cred_hist_length': 14\n",
        "}\n",
        "\n",
        "# Preprocess the user input data\n",
        "processed_input = preprocess_input(user_input)\n",
        "\n",
        "# Get the predicted acceptance probability\n",
        "predicted_acceptance = predict_acceptance(processed_input)\n",
        "\n",
        "# Output the predicted probability of loan approval\n",
        "print(f\"The predicted probability of loan approval is: {predicted_acceptance * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7RYyylt9JQP",
        "outputId": "21fdee5f-4e1a-4b7b-fc45-d9c9fb1c4705"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted probability of loan approval is: 57.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "\n",
        "# Function to create the model\n",
        "def create_model(input_dim):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')  # Sigmoid activation for binary classification\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# 5-Fold Cross-Validation and Collecting Test Predictions\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Arrays to store the performance metrics and test predictions for each fold\n",
        "fold_accuracy = []\n",
        "fold_loss = []\n",
        "test_preds = []\n",
        "\n",
        "# Early Stopping Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# For storing the best model\n",
        "best_model = None\n",
        "best_val_accuracy = 0\n",
        "\n",
        "# Stratified K-Fold Cross-Validation\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(X_np, y_np)):\n",
        "    print(f\"\\nFold {fold + 1}\")\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    X_train_fold, X_val_fold = X_np[train_index], X_np[val_index]\n",
        "    y_train_fold, y_val_fold = y_np[train_index], y_np[val_index]\n",
        "\n",
        "    # Feature Scaling within each fold\n",
        "    scaler = StandardScaler()\n",
        "    X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
        "    X_val_fold_scaled = scaler.transform(X_val_fold)\n",
        "    test_scaled = scaler.transform(test.values)\n",
        "\n",
        "    # Build the model\n",
        "    model = create_model(input_dim=X_train_fold_scaled.shape[1])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train_fold_scaled, y_train_fold,\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_val_fold_scaled, y_val_fold),\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X_val_fold_scaled, y_val_fold, verbose=0)\n",
        "    print(f'Validation Loss for fold {fold + 1}: {loss:.4f}')\n",
        "    print(f'Validation Accuracy for fold {fold + 1}: {accuracy:.4f}')\n",
        "\n",
        "    fold_accuracy.append(accuracy)\n",
        "    fold_loss.append(loss)\n",
        "\n",
        "    # Save the model after each fold (optional)\n",
        "    model_save_path = f'model_fold_{fold + 1}.h5'\n",
        "    model.save(model_save_path)\n",
        "    print(f\"Model for fold {fold + 1} saved.\")\n",
        "\n",
        "    # If this is the best model so far, save it as the best model\n",
        "    if accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = accuracy\n",
        "        best_model = model\n",
        "        model.save('best_model.h5')\n",
        "        print(f\"Best model saved with validation accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    test_pred = model.predict(test_scaled)\n",
        "    test_preds.append(test_pred)\n",
        "\n",
        "# After all folds\n",
        "print('\\nCross-validation results:')\n",
        "print(f'Average Validation Accuracy: {np.mean(fold_accuracy):.4f}')\n",
        "print(f'Standard Deviation of Validation Accuracy: {np.std(fold_accuracy):.4f}')\n",
        "print(f'Average Validation Loss: {np.mean(fold_loss):.4f}')\n",
        "print(f'Standard Deviation of Validation Loss: {np.std(fold_loss):.4f}')\n",
        "\n",
        "# Aggregate test predictions\n",
        "test_preds = np.array(test_preds)  # Shape: (n_folds, n_samples, 1)\n",
        "# Average the predictions across folds\n",
        "test_predictions_mean = np.mean(test_preds, axis=0).flatten()\n",
        "\n",
        "# Convert averaged predictions to binary (0 or 1)\n",
        "test_predictions_binary = (test_predictions_mean >= 0.5).astype(int)\n",
        "\n",
        "# If desired, save the final model (trained on all data)\n",
        "final_model = create_model(input_dim=X_np.shape[1])\n",
        "final_model.fit(X_np, y_np, epochs=100, batch_size=32, verbose=1)\n",
        "final_model.save('final_model.h5')\n",
        "print(\"Final model saved after training on all data.\")\n",
        "\n",
        "# Optionally, load the best model if needed\n",
        "# model = load_model('best_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2g1KNF6z9lUP",
        "outputId": "805173d0-48e5-4897-f154-8abe648dc3ed"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8235 - loss: 0.4718 - val_accuracy: 0.9260 - val_loss: 0.1979\n",
            "Epoch 2/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2468 - val_accuracy: 0.9282 - val_loss: 0.1850\n",
            "Epoch 3/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9304 - loss: 0.2176 - val_accuracy: 0.9287 - val_loss: 0.1811\n",
            "Epoch 4/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9321 - loss: 0.2070 - val_accuracy: 0.9344 - val_loss: 0.1767\n",
            "Epoch 5/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9330 - loss: 0.2078 - val_accuracy: 0.9342 - val_loss: 0.1715\n",
            "Epoch 6/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9369 - loss: 0.1974 - val_accuracy: 0.9406 - val_loss: 0.1670\n",
            "Epoch 7/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.1958 - val_accuracy: 0.9453 - val_loss: 0.1649\n",
            "Epoch 8/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.1934 - val_accuracy: 0.9477 - val_loss: 0.1617\n",
            "Epoch 9/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9391 - loss: 0.1923 - val_accuracy: 0.9510 - val_loss: 0.1631\n",
            "Epoch 10/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.1872 - val_accuracy: 0.9497 - val_loss: 0.1630\n",
            "Epoch 11/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9424 - loss: 0.1849 - val_accuracy: 0.9520 - val_loss: 0.1574\n",
            "Epoch 12/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1745 - val_accuracy: 0.9501 - val_loss: 0.1585\n",
            "Epoch 13/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.1807 - val_accuracy: 0.9534 - val_loss: 0.1576\n",
            "Epoch 14/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.1819 - val_accuracy: 0.9548 - val_loss: 0.1543\n",
            "Epoch 15/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9445 - loss: 0.1779 - val_accuracy: 0.9518 - val_loss: 0.1571\n",
            "Epoch 16/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.1808 - val_accuracy: 0.9552 - val_loss: 0.1520\n",
            "Epoch 17/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.1790 - val_accuracy: 0.9534 - val_loss: 0.1527\n",
            "Epoch 18/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9470 - loss: 0.1710 - val_accuracy: 0.9524 - val_loss: 0.1563\n",
            "Epoch 19/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9441 - loss: 0.1809 - val_accuracy: 0.9523 - val_loss: 0.1553\n",
            "Epoch 20/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.1702 - val_accuracy: 0.9527 - val_loss: 0.1522\n",
            "Epoch 21/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.1751 - val_accuracy: 0.9504 - val_loss: 0.1593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss for fold 1: 0.1520\n",
            "Validation Accuracy for fold 1: 0.9552\n",
            "Model for fold 1 saved.\n",
            "Best model saved with validation accuracy: 0.9552\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\n",
            "Fold 2\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.3697 - val_accuracy: 0.9260 - val_loss: 0.2057\n",
            "Epoch 2/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2373 - val_accuracy: 0.9310 - val_loss: 0.1921\n",
            "Epoch 3/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.2228 - val_accuracy: 0.9337 - val_loss: 0.1843\n",
            "Epoch 4/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9335 - loss: 0.2012 - val_accuracy: 0.9296 - val_loss: 0.1836\n",
            "Epoch 5/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9334 - loss: 0.2002 - val_accuracy: 0.9460 - val_loss: 0.1782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss for fold 2: 0.2057\n",
            "Validation Accuracy for fold 2: 0.9260\n",
            "Model for fold 2 saved.\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\n",
            "Fold 3\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8845 - loss: 0.3675 - val_accuracy: 0.9260 - val_loss: 0.2054\n",
            "Epoch 2/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.2377 - val_accuracy: 0.9313 - val_loss: 0.1876\n",
            "Epoch 3/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.2158 - val_accuracy: 0.9343 - val_loss: 0.1809\n",
            "Epoch 4/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9329 - loss: 0.2015 - val_accuracy: 0.9360 - val_loss: 0.1778\n",
            "Epoch 5/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9318 - loss: 0.2002 - val_accuracy: 0.9377 - val_loss: 0.1744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss for fold 3: 0.2054\n",
            "Validation Accuracy for fold 3: 0.9260\n",
            "Model for fold 3 saved.\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\n",
            "Fold 4\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.3968 - val_accuracy: 0.9260 - val_loss: 0.2026\n",
            "Epoch 2/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 0.2451 - val_accuracy: 0.9269 - val_loss: 0.1904\n",
            "Epoch 3/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.2233 - val_accuracy: 0.9374 - val_loss: 0.1830\n",
            "Epoch 4/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9325 - loss: 0.2090 - val_accuracy: 0.9374 - val_loss: 0.1798\n",
            "Epoch 5/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9320 - loss: 0.2026 - val_accuracy: 0.9393 - val_loss: 0.1764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss for fold 4: 0.2026\n",
            "Validation Accuracy for fold 4: 0.9260\n",
            "Model for fold 4 saved.\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\n",
            "Fold 5\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3979 - val_accuracy: 0.9260 - val_loss: 0.1916\n",
            "Epoch 2/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2371 - val_accuracy: 0.9334 - val_loss: 0.1772\n",
            "Epoch 3/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.2171 - val_accuracy: 0.9284 - val_loss: 0.1801\n",
            "Epoch 4/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.2185 - val_accuracy: 0.9400 - val_loss: 0.1732\n",
            "Epoch 5/100\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9361 - loss: 0.1964 - val_accuracy: 0.9502 - val_loss: 0.1659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss for fold 5: 0.1916\n",
            "Validation Accuracy for fold 5: 0.9260\n",
            "Model for fold 5 saved.\n",
            "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\n",
            "Cross-validation results:\n",
            "Average Validation Accuracy: 0.9319\n",
            "Standard Deviation of Validation Accuracy: 0.0117\n",
            "Average Validation Loss: 0.1915\n",
            "Standard Deviation of Validation Loss: 0.0204\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-ad137eed31ae>\u001b[0m in \u001b[0;36m<cell line: 111>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m# If desired, save the final model (trained on all data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final model saved after training on all data.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
          ]
        }
      ]
    }
  ]
}